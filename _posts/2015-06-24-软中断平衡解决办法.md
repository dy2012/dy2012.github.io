---

layout: post

title:  软中断平衡的解决办法

tags: [性能调优]

---

####软中断平衡
&emsp;&emsp;irqbalance用于优化中断分配，它会自动收集系统数据以分析使用模式，并依据系统负载状况将工作状态置于Performance mode或Power-save mode，处于Performance mode时，irqbalance 会将中断尽可能均匀地分发给各个CPU core，以充分利用CPU多核，提升性能，处于Power-save mode时，irqbalance会将中断集中分配给第一个CPU，以保证其它空闲CPU的睡眠时间，降低能耗，但实际中往往影响CPU的使用均衡，建议服务器环境中关闭。

&emsp;&emsp;在实际项目中发现cpu0的占用率很高，通过mpstat –P ALL 1 间隔1s刷新，可以观察到单核cpu的负载情况，为了保证索引服务器能够将负载尽量均衡的分配到每个cpu core上，并减少延迟，合理的根据自己的生产环境和应用特点来平衡IRQ中断有助于提高系统的整体吞吐能力和性能。


####具体操作流程

&emsp;&emsp;在手动绑定IRQ到CPU之前需要先停掉irqbalance这个服务。否则设置不生效，由于机器是16个core，开启HT后32逻辑核心，smp_affinity默认是分配到前16个cpu上。

    /etc/init.d/irqbalance stop  
用下面的命令来查看网卡是不是支持多队列
    
    lspci -vvv | grep -i msi-x    
 
 ![](http://dy2012.github.io/graphics/msi.png)

多队列网卡一般支持多个中断号，可以将多个中断号绑定到除了cpu0以外的cpu。

    cat /proc/interrupts | grep eth0

![](http://dy2012.github.io/graphics/irq.png)

可以看到最左边121，122，123，124，125为中断号，我们可以分别将中断号分到不同的cpu，从而减少负载。

    echo "${cpu.no}" > /proc/irq/${num}/smp_affinity
绑定cpu，cpu.no是cpu0为2^0, cpu1为2^1，cpu2为2^2… 比如，我将网卡的多路中断绑定到5个不同的CPU来平衡中断：

    echo “2” > /proc/irq/121/smp_affinity      
    echo “4” > /proc/irq/122/smp_affinity
    echo “8” > /proc/irq/123/smp_affinity
    echo “16” > /proc/irq/124/smp_affinity
    echo “32” > /proc/irq/125/smp_affinity
